{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a1a59a",
   "metadata": {},
   "source": [
    "# Ebuss: Sentiment-based Product Recommendation System\n",
    "\n",
    "This notebook covers:\n",
    "- EDA + Cleaning\n",
    "- Sentiment model training (LogReg / Naive Bayes / Random Forest code)\n",
    "- User-based vs Item-based recommender (we deploy Item-based)\n",
    "- Sentiment-filtered top-5 recommendations\n",
    "- Deployment steps (Flask + Heroku)\n",
    "\n",
    "**Deployment link (replace after you deploy):** `https://<your-heroku-app>.herokuapp.com/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff03c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = 'sample30.csv'\n",
    "ATTR_PATH = 'Data+Attribute+Description.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "attr = pd.read_csv(ATTR_PATH, encoding='latin1')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute descriptions\n",
    "attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a81b430",
   "metadata": {},
   "source": [
    "## 1) EDA and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa87bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa49d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_rating'] = pd.to_numeric(df['reviews_rating'], errors='coerce')\n",
    "print(df['reviews_rating'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47149d84",
   "metadata": {},
   "source": [
    "## 2) Text preprocessing and feature extraction\n",
    "We use TF-IDF over a hashing-based vectorizer for speed and easy deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_full'] = (df['reviews_title'].fillna('').astype(str) + ' ' + df['reviews_text'].fillna('').astype(str)).str.strip()\n",
    "\n",
    "df['user_sentiment'] = df['user_sentiment'].astype(str).str.lower()\n",
    "sent_df = df[df['user_sentiment'].isin(['positive','negative'])].copy().reset_index(drop=True)\n",
    "y = (sent_df['user_sentiment'] == 'positive').astype(int)\n",
    "X = sent_df['review_full']\n",
    "print('Class balance:', y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f7c61",
   "metadata": {},
   "source": [
    "## 3) Train at least 3 models\n",
    "Below we include code for:\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Random Forest (heavier; run in Colab for faster compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc498f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "hv = HashingVectorizer(stop_words='english', n_features=2**14, alternate_sign=False, ngram_range=(1,2))\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "def evaluate(pipe):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    prob = pipe.predict_proba(X_test)[:,1]\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, pred),\n",
    "        'f1': f1_score(y_test, pred),\n",
    "        'roc_auc': roc_auc_score(y_test, prob)\n",
    "    }\n",
    "\n",
    "pipelines = {\n",
    "    'log_reg': Pipeline([('hash', hv), ('tfidf', tfidf), ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'))]),\n",
    "    'naive_bayes': Pipeline([('hash', hv), ('tfidf', tfidf), ('clf', MultinomialNB())]),\n",
    "    'random_forest': Pipeline([('hash', hv), ('tfidf', tfidf), ('clf', RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced_subsample', n_jobs=-1))])\n",
    "}\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    print(name, evaluate(pipe))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce93cdec",
   "metadata": {},
   "source": [
    "Pick the best performing classifier (often Logistic Regression). Save it as a pickle for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd199b3",
   "metadata": {},
   "source": [
    "## 4) Recommendation system\n",
    "We build and compare:\n",
    "- User-based CF\n",
    "- Item-based CF\n",
    "\n",
    "We deploy **Item-based CF** because the number of products is much smaller than the number of users (more scalable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "ratings_df = df.dropna(subset=['reviews_rating','reviews_username','name']).copy()\n",
    "ratings_df['reviews_username'] = ratings_df['reviews_username'].astype(str)\n",
    "ratings_df['name'] = ratings_df['name'].astype(str)\n",
    "\n",
    "user_item = ratings_df.pivot_table(index='reviews_username', columns='name', values='reviews_rating', aggfunc='mean')\n",
    "user_item_filled = user_item.fillna(0.0)\n",
    "R = sparse.csr_matrix(user_item_filled.values)\n",
    "\n",
    "users = user_item_filled.index.tolist()\n",
    "items = user_item_filled.columns.tolist()\n",
    "\n",
    "# Item-item similarity (items x users)\n",
    "S = cosine_similarity(R.T, dense_output=True)\n",
    "np.fill_diagonal(S, 0.0)\n",
    "print('Users:', len(users), 'Items:', len(items), 'S shape:', S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recommend_20(username, n=20):\n",
    "    if username not in users:\n",
    "        return []\n",
    "    uidx = users.index(username)\n",
    "    user_r = R.getrow(uidx).toarray().ravel()\n",
    "    rated = user_r > 0\n",
    "    sims = S[:, rated]\n",
    "    ratings = user_r[rated]\n",
    "    if ratings.size == 0:\n",
    "        return []\n",
    "    scores = sims.dot(ratings) / (np.abs(sims).sum(axis=1) + 1e-9)\n",
    "    scores[rated] = -np.inf\n",
    "    top_idx = np.argsort(-scores)[:n]\n",
    "    return [items[i] for i in top_idx if np.isfinite(scores[i])]\n",
    "\n",
    "# Example\n",
    "example_user = users[0]\n",
    "recommend_20(example_user, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e6e5a",
   "metadata": {},
   "source": [
    "## 5) Sentiment-filtered Top-5\n",
    "Take the top-20 from CF and pick the top-5 with the highest average positive sentiment over the product's reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee497e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume `best_sentiment_model` is your chosen pipeline from section 3.\n",
    "# For each product, compute average positive probability across reviews.\n",
    "\n",
    "def avg_positive_sentiment(product_name, model):\n",
    "    texts = df.loc[df['name'] == product_name, 'review_full'].dropna().astype(str).tolist()\n",
    "    if not texts:\n",
    "        return 0.0\n",
    "    probs = model.predict_proba(texts)[:,1]\n",
    "    return float(np.mean(probs))\n",
    "\n",
    "def recommend_5(username, model):\n",
    "    top20 = recommend_20(username, 20)\n",
    "    scored = [(p, avg_positive_sentiment(p, model)) for p in top20]\n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [p for p, s in scored[:5]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8c3a7",
   "metadata": {},
   "source": [
    "## 6) Deployment\n",
    "You will submit:\n",
    "- Notebook\n",
    "- `model.py`, `app.py`, `templates/index.html`\n",
    "- Pickle files\n",
    "\n",
    "**Heroku link:** replace this after deployment: `https://<your-heroku-app>.herokuapp.com/`"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
